# Python 深度学习笔记

记录一些写代码的经验，而不是系统的学习 Python。

如果想要快速的发现自己对于 Python 数据处理有哪些重要的内容不熟悉，可以对照经典的“NumPy 100 题”。

## 1. 带变量字符串的输出

使用 f-string（字符串前缀为 f ）来格式化字符串，可以在字符串中直接使用变量和表达式，使用大括号 {} 作为占位符。

```python
name = "John"
age = 25
print(f"My name is {name} and I'm {age} years old.")

'''
运行结果：
My name is John and I'm 25 years old.
'''
```

这是最简洁的一种方法，但是 Python 3.6 才支持。

> 还有其他两种，见过但是不常用：
>
> （1）使用百分号（%）作为占位符，后面跟上相应类型的字母表示变量类型，如%s表示字符串，%d表示整数，%f表示浮点数等。（这种写法感觉和 C、C++ 的 printf 很像。）
>
> ```python
> name = "John"
> age = 25
> print("My name is %s and I'm %d years old." % (name, age))
> ```
>
> (2) 使用 format() 方法来格式化字符串，使用大括号 {} 作为占位符，可以在 {} 中指定参数的位置或者名称。
>
> ```python
> name = "John"
> age = 25
> print("My name is {} and I'm {} years old.".format(name, age))
> ```

## 2. Python 中常用的数据结构

### 列表（List）

可以容纳不同类型的元素，并且支持动态扩展和缩小。

```python
my_list = [1, 2, 3, 4, 5]    # 创建列表
my_list.append(6)            # 在列表末尾添加元素
my_list.extend([7, 8, 9])    # 在列表末尾添加多个元素
my_list.pop()                # 移除列表末尾的元素
print(my_list)               # [1, 2, 3, 4, 5, 6, 7, 8]

'''
输出结果：
[1, 2, 3, 4, 5, 6, 7, 8]
'''
```

### 元组（Tuple）

元组与列表类似，但是元组是不可变的，一旦创建就不能修改。

```python
my_tuple = (1, 2, 3, 4, 5)    # 创建元组
print(my_tuple)
print(my_tuple[0])            # 访问元组中的元素

'''
输出结果：
(1, 2, 3, 4, 5)
1
'''
```

### 集合（Set）

集合用于存储不同的元素，没有顺序，并且不允许重复元素。

```python
my_set = {1, 2, 3, 4, 5}    # 创建集合
my_set.add(6)               # 添加元素到集合中
my_set.update([7, 8, 9])    # 添加多个元素到集合中
my_set.remove(1)            # 从集合中移除元素
print(my_set)               # {2, 3, 4, 5, 6, 7, 8, 9}

'''
输出结果：
{2, 3, 4, 5, 6, 7, 8, 9}
'''
```

### NumPy 数组（NumPy Array）

NumPy 数组用于存储同类型的数值数据，数组可以是一维或多维的，支持各种数值运算和操作。

```python
my_array = np.array([1, 2, 3, 4, 5])    # 创建一维数组
print(my_array.shape)                   # 输出数组的形状
print(my_array[0])                      # 访问数组中的元素
my_matrix = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])    # 创建二维数组
print(my_matrix.shape)                                    # 输出数组的形状

'''
输出结果：
(5,)
1
(3, 3)
'''
```

### Pandas 数据帧（Pandas DataFrame）

Pandas 数据帧用于处理结构化数据，类似于数据库中的表格，可以进行各种数据操作和分析。

```python
import pandas as pd
my_df = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6]})    # 创建数据帧
print(my_df)                                              # 输出数据帧的内容
print()
print(my_df['a'])                                         # 访问数据帧中的列
print()
print(my_df.loc[0])                                       # 访问数据帧中的行

'''
输出结果：
   a  b
0  1  4
1  2  5
2  3  6

0    1
1    2
2    3
Name: a, dtype: int64

a    1
b    4
Name: 0, dtype: int64
'''
```

### PyTorch 张量（PyTorch Tensor）

PyTorch 张量用于存储和处理多维数组，支持各种数值运算和深度学习相关操作，是深度学习中常用的数据结构。

```python
import torch
my_tensor = torch.tensor([1, 2, 3, 4, 5])    # 创建一维张量
print(my_tensor.shape)                       # 输出张量的形状
print(my_tensor[0])                          # 访问张量中的元素
my_matrix = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])    # 创建二维张量
print(my_matrix.shape)                                        # 输出张量的形状

'''
输出结果：
torch.Size([5])
tensor(1)
torch.Size([3, 3])
'''
```

## 3. 常用生成数组方法

### np.zeros(shape, dtype=float, order='C', *, like = None)

- 参数 `shape` 是一个整数或**元组（用括号括起来）**。
- `dtype` 指定数据类型
- `order` 和 `like` 实在不常用，不管了。
- 实际上应该是：`numpy.zeors()`。。。

```python
# 长度为 10 的全 0 数组（也就是 numpy array）
a = np.zeros(10)
print(f"np.zeros(10): {a}")
x = np.zeros((2,3), int)
print(x)

'''
输出结果：
np.zeros(10): [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
[[0 0 0]
 [0 0 0]]
'''
```

### np.ones(shape, dtype=float, order='C', *, like = None)


```python
# 长度为 10 的全 1 数组
a = np.ones(10)
print(f"np.ones(10): {a}")

'''
输出结果：
np.ones(10): [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
'''
```

### np.arange([start,] stop, [step,] dtype=None, *, like = None)

- `start` ： 开始位置
- `stop` ：结束位置
- `step` ：步长

```python
# 只有一个参数的时候，认为是右侧开区间的值，即 stop 值，左侧为 0
a = np.arange(10)
print(f"np.arange(10): {a}")
# 生成 x 到 y 左闭右开的整数序列
a = np.arange(10, 20)
print(f"np.arange(10, 20): {a}")
# 加步长 step
a = np.arange(10, 20, 2)
print(f"np.arange(10, 20, 2): {a}")

'''
输出结果：
np.arange(10): [0 1 2 3 4 5 6 7 8 9]
np.arange(10, 20): [10 11 12 13 14 15 16 17 18 19]
np.arange(10, 20, 2): [10 12 14 16 18]
'''
```

### np.eye(N, M=None, k=0, dtype=<class 'float'>, order='C', *, like = None)

- numpy.eye() 函数可以生成非方阵对应的的“单位矩阵”。
- k 表示对角线的偏移量

```python
# 创建 3*3 的单位矩阵
a = np.eye(3)
print(f"np.eye(3): {a}")
a = np.eye(2,3, 0, int)
print(f"np.eye(2,3, 0, int)): {a}")

'''
输出结果：
np.eye(3): [[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
np.eye(2,3, 0, int)): [[1 0 0]
 [0 1 0]]
'''
```

### torch.zeros(size, dtype=None, layout=torch.strided, device=None, requires_grad=False)

其实更准确的写法是：`torch.zeros(*size, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) → Tensor`。这个是文档中的写法，感觉也没必要这样记。但是，由于 tensor 初始化用的参数实在太多，建议初始化的时候写明参数具体是哪一个，如：

```python
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
x = torch.zeros((2,3), dtype=float, device=device, requires_grad=True)
print(x)
'''
tensor([[0., 0., 0.],
        [0., 0., 0.]], device='cuda:0', dtype=torch.float64,
       requires_grad=True)
'''
```

### torch.ones(size, dtype=None, layout=torch.strided, device=None, requires_grad=False)

```python
x = torch.ones((2,3), dtype=float, device=device, requires_grad=True)
print(x)
'''
tensor([[1., 1., 1.],
        [1., 1., 1.]], device='cuda:0', dtype=torch.float64,
       requires_grad=True)      
'''
```

### torch.arange(start=0, end, step=1, dtype=None, layout=torch.strided, device=None, requires_grad=False)

```python
x = torch.arange(10)
print(x)
x = torch.arange(5,15,2)
print(x)
'''
tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])
tensor([ 5,  7,  9, 11, 13])
'''
```

> np.random.rand()、np.random.randn() 等方法也常常用来初始化一个数组，在下一部分中介绍。

## 4.常用生成随机数方法

与 `zeros()` 等方法不同，`rand()`、`randn()` 等方法指定维度直接写整数值。PyTorch 如果有其他需要的参数如 device 等，再后面指明。

### np.random.rand()

生成指定形状的 [0, 1) 之间的**均匀分布**随机数。

```python
# 生成一个形状为 (2, 3) 的随机矩阵
random_matrix = np.random.rand(2, 3)  
print(random_matrix)

'''
输出结果：
[[0.50798051 0.87201926 0.00998055]
 [0.07587565 0.15509911 0.76343724]]
'''
```

> 额外介绍: np.random.random()
>
> 这个函数同样生成指定形状的 [0, 1) 之间的均匀分布随机数。但是参数接收不同，和 zeros 等一致接收一个元组，例如：
>
> ```python
> a = np.random.random((2, 3))
> print(a)
> 
> '''
> 输出结果：
> [[0.2830632  0.85411065 0.95795635]
>  [0.44640965 0.92036816 0.114604  ]]
> '''
> ```

### np.random.randn()

生成指定形状的**标准正态分布随机数**，均值为 0，方差为 1。

```python
# 生成一个形状为 (2, 3) 的标准正态分布随机矩阵
random_matrix = np.random.randn(2, 3)  
print(random_matrix)

'''
输出结果：
[[ 2.50382043 -0.89433515  0.0480158 ]
 [-1.49484424 -1.49208708  0.66633548]]
'''
```

### np.random.randint()

生成**指定范围**内的**整数**随机数。

```python
# 生成一个在 [0, 10) 范围内的整数随机数
random_int = np.random.randint(10)  
print(random_int)

# 生成一个在 [0, 10) 范围内的形状为 (2, 3) 的整数随机矩阵
random_matrix = np.random.randint(10, size=(2, 3))  
print(random_matrix)

# 生成一个在 [5, 10) 范围内的形状为 (2, 3) 的整数随机矩阵
random_matrix = np.random.randint(5, 10, size=(2, 3))  
print(random_matrix)


'''
输出结果：
7
[[2 8 2]
 [6 5 9]]
[[8 5 7]
 [6 6 6]]
'''
```

### np.random.choice()

从给定序列中随机选择元素。

```python
# 从 [1, 2, 3, 4, 5] 中随机选择 2 个元素
random_choice = np.random.choice([1, 2, 3, 4, 5], size=2)  
print(random_choice)

'''
输出结果：
[5 4]
'''
```

### np.random.shuffle()

随机打乱序列中的元素。

需要注意的是，`np.random.shuffle()` 函数并没有返回值，而是原地打乱。`arr = np.random.shuffle(arr)` 会得到一个 `null` 值。

```python
# 打乱 [1, 2, 3, 4, 5] 序列中的元素
arr = np.array([1, 2, 3, 4, 5])
np.random.shuffle(arr)
print(arr)

'''
输出结果：
[5 4 3 1 2]
'''
```

### torch.rand()、torch.randn()、torch.randint()

与 numpy 中方法一致

```python
import torch

# torch.rand()
random_matrix = torch.rand(2, 3, requires_grad=True)
print(random_matrix)

# torch.randn()  
random_matrix = torch.randn(2, 3)  
print(random_matrix)

# torch.randint()
# 注意参数的写法
random_int = torch.randint(10, size=(1,))  
print(random_int.item())
random_matrix = torch.randint(10, size=(2, 3))  
print(random_matrix)

'''
tensor([[0.8694, 0.5677, 0.7411],
        [0.4294, 0.8854, 0.5739]], requires_grad=True)
tensor([[ 0.3930,  0.4327, -1.3627],
        [ 1.3564,  0.6688, -0.7077]])
2
tensor([[0, 5, 9],
        [3, 4, 9]])
'''
```

### torch.randperm()

生成一个范围内的随机整数排列。

shape 的参数只支持一个上界，其他参数如 `device` 等与 `torch.zeros()` 、`torch.rand()` 等方法一致。

```python
# 生成一个 0 到 4 的随机排列
random_perm = torch.randperm(5)  
print(random_perm)

'''
运行结果：
tensor([4, 3, 2, 0, 1])
'''
```

这个实现 numpy 中类似 `np.random.shuffle()` 函数的功能。

### torch.manual_seed()

设置随机数种子，用于生成可重复的伪随机数。

需要注意的是，设置种子之后，每次运行文件可以得到相同的随机数，而不是运行随机函数得到相同的随机数。例如以下代码，多次在 python 环境中运行，保证得到的随机数不变。这种设计与此函数的意义也是符合的，即多次运行文件得到相同的结果。

```python
import torch

# 设置随机数种子
torch.manual_seed(42)

# 生成两个随机矩阵，由于种子相同，因此结果相同
random_matrix1 = torch.rand(2, 3)  
random_matrix2 = torch.rand(2, 3)  
print(random_matrix1)
print(random_matrix2)

'''
输出结果：
tensor([[0.8823, 0.9150, 0.3829],
        [0.9593, 0.3904, 0.6009]])
tensor([[0.2566, 0.7936, 0.9408],
        [0.1332, 0.9346, 0.5936]])
'''
```

## 5. 切片

可以参考这个回答：[Python 切片完全指南(语法篇) - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/79541418)

简单概括主要的内容为：

- 一个冒号的，表示 a[start : stop]

- 两个冒号的，表示 a[start : stop: step]
- start 和 stop为下标，左闭右开；除了常规的下标还有负下标，也是递增，最大的也就是最右侧一个是 -1
- 如果 step < 0，则要求 start > stop，表示按照逆序取数；逆序取数的时候，stop 的位置同样是开区间
- start 和 stop 为空时，默认为无穷大。注意，当 step < 0 时，start 的缺省值为无穷大，stop 的缺省值为无穷小。 
- start 和 stop 超出索引范围的时候，会认为：“能取到这个位置，但是最后这个位置没数，没保留”

```python
# 一些常见的例子
a = np.arange(10)
print(a[2:5])
print(a[5:2:-1])
print(a[2:-1]) # -1 是最大的负数下标
print(a[2:100])
print(a[::2])
print(a[::-1])

'''
输出结果：
[2 3 4]
[5 4 3]
[2 3 4 5 6 7 8]
[2 3 4 5 6 7 8 9]
[0 2 4 6 8]
[9 8 7 6 5 4 3 2 1 0]
'''
```

切片还有很多看起来非常费解的操作，但是也十分不常用，还是记住最常用的这些并理解好。

## 6. shape 转换与输出

### reshape

```python
# numpy
a = np.arange(6).reshape(2, 3)
print(a)
# pytorch
x = torch.arange(6).reshape(2, 3)
print(x)
'''
[[0 1 2]
 [3 4 5]]
tensor([[0, 1, 2],
        [3, 4, 5]])
'''
```

### 输出 shape

注意输出 shape 后面不带括号。

```python
# numpy
a = np.arange(6).reshape(2, 3)
print(a.shape)
# pytorch
x = torch.arange(6).reshape(2, 3)
print(x.shape)
# list
a = [[1,2,3],[4,5,6]]
print(len(a))
print(len(a[0]))
'''
(2, 3)
torch.Size([2, 3])
2
3
'''
```

## 7. 基本数据类型、类型转换

### NumPy

1. `bool`: 布尔类型，只能取 `True` 或 `False` 两个值。
2. `int8`, `int16`, `int32`, `int64`: 整数类型，分别占用 1、2、4、8 个字节。
3. `float16`, `float32`, `float64`: 浮点数类型，分别占用 2、4、8 个字节。
4. 还有 `uint8` （无符号整数）、`complex64`（复数）等。

使用 `.astype()` 方法来进行类型转换。

```python
# 创建一个整型数组
a = np.array([1, 2, 3], dtype=np.int32)
print(a)
x = a.astype(np.float32)
print(x)

# 创建一个浮点型数组
b = np.array([1.0, 2.0, 3.0], dtype=np.float32)
print(b)
y = b.astype(np.int32)
print(y)

# 类型也可以直接写 int、float 等
a = np.array([1, 2, 3], dtype=int)
print(a)
x = a.astype(float)
print(x)

'''
[1 2 3]
[1. 2. 3.]
[1. 2. 3.]
[1 2 3]
[1 2 3]
[1. 2. 3.]
'''
```

### PyTorch

1. `torch.float32`, `torch.float64`: 浮点数类型，分别占用 4、8 个字节。
2. `torch.int8`, `torch.int16`, `torch.int32`, `torch.int64`: 整数类型，分别占用 1、2、4、8 个字节。
3. `torch.bool`: 布尔类型，只能取 `True` 或 `False` 两个值。
4. 也有 `torch.int8`、`torch.complex64` 等。

使用 `.to()` 方法来进行类型转换。

```python
# 创建一个整型张量
a = torch.tensor([1, 2, 3], dtype=torch.int32)
print(a)
# 将整型张量转换为浮点型张量
x = a.to(torch.float32)
print(x)

# 创建一个浮点型张量
b = torch.randn(2,3, requires_grad=True, dtype=torch.float32)
print(b)
# 将浮点型张量转换为整型张量
y = x.to(torch.int32)
print(y)

# dtype 参数写 torch.int32 太复杂，可以写 int、float
x = torch.randn(2, 3, dtype=float)
print(x)
a = x.to(int)
print(a)

'''
tensor([1, 2, 3], dtype=torch.int32)
tensor([1., 2., 3.])
tensor([[-0.6382, -1.9187, -0.6441],
        [-0.6061, -0.1425,  0.9727]], requires_grad=True)
tensor([1, 2, 3], dtype=torch.int32)
tensor([[ 2.0038,  0.6622,  0.5332],
        [ 2.7489, -0.3841, -1.9623]], dtype=torch.float64)
tensor([[ 2,  0,  0],
        [ 2,  0, -1]])
'''
```

## 8. 数据存储结构转换

### NumPy array 与 PyTorch Tensor 转换

都是用的 torch 中的方法。

- 将 NumPy array 转换为 PyTorch Tensor 可以使用 `torch.from_numpy()` 函数。
- 将 PyTorch Tensor 转换为 NumPy array 可以使用 `.numpy()` 方法。

```python
a = np.randn(2,3)
print(a)
x = torch.from_numpy(a)
print(x)

y = torch.randn(2,3,dtype=float)
print(y)
```

需要注意的是，NumPy array 和 PyTorch Tensor 之间的转换会共享底层数据存储，因此在转换后修改其中一个对象的值可能会影响另一个对象的值。如果需要避免这种情况，可以使用 `.copy()` 方法来进行复制。

```python
a = np.array([[1, 2], [3, 4]]) # 这里是传入一个 list 创建，也相当于将 list 转换为 array
x = torch.from_numpy(a)
a[0][0] = 0
print(a)
print(x)

b = np.array([1,2,3])
y = torch.from_numpy(b).clone()
b[0] = 0
print(b)
print(y)

'''
[[0 2]
 [3 4]]
tensor([[0, 2],
        [3, 4]], dtype=torch.int32)
[0 2 3]
tensor([1, 2, 3], dtype=torch.int32)
'''
```

### List 和 NumPy array 转换

分别调用的 numpy 的方法和 list 的方法

```python
# list 转换为 numpy
# 这种方法也是一种常见的创建 numpy array 的方式
a = [1, 2, 3]
b = np.array(a)
print(a)
print(b)

# numpy 转换为 list
a = np.random.randn(3)
b = list(a)
print(a)
print(b)

'''
[1, 2, 3]
[1 2 3]
[0.50463248 1.1060088  1.64139073]
[0.5046324821437648, 1.1060088035305, 1.6413907334280997]
'''
```

## 数据统计常用函数

- `.min()` 或者 `min(a)`
- `.max()`

```python
# NumPy
a = np.arange(5, 10)
print(a)
np.random.shuffle(a)
print(a)
print(a.max())
print(a.min())
print(min(a))

# PyTorch
x = torch.randperm(5)
print(x)
print(x.min())
print(x.max())

'''
[5 6 7 8 9]
[5 7 6 8 9]
9
5
5
tensor([3, 4, 2, 1, 0])
tensor(0)
tensor(4)
'''
```

类似的函数还有：

- 求和：`np.sum(x)`
- 均值：`np.mean(x)`
- 标准差：`np.std(x)`

```python
# numpy
a = np.arange(5, 10)
print(a)
a.astype(float)
print(a.sum())
print(sum(a))
print(a.mean())
print(a.std())

# PyTorch
x = torch.randperm(5)
print(x)
x = x.to(float)
print(x.sum())
print(sum(x))
print(x.mean())
print(x.std())

'''
[5 6 7 8 9]
35
35
7.0
1.4142135623730951
tensor([4, 0, 1, 3, 2])
tensor(10., dtype=torch.float64)
tensor(10., dtype=torch.float64)
tensor(2., dtype=torch.float64)
tensor(1.5811, dtype=torch.float64)
'''
```

## 常用线性代数运算

### 基本算数运算 or 逐元素计算

直接进行加减乘除运算即可完成。

```python
# numpy
a = np.arange(1, 10).reshape(3, 3)
b = np.arange(3, 12).reshape(3, 3)
a.astype(float)
b.astype(float)
print(a + b)
print(a - b)
print(a * b)
print(a / b)

# PyTorch
x = torch.arange(1, 10).reshape(3, 3)
y = torch.arange(3, 12).reshape(3, 3)
x.to(float)
y.to(float)
print(x + y)
print(x - y)
print(x * y)
print(x / y)
'''
[[ 4  6  8]
 [10 12 14]
 [16 18 20]]
[[-2 -2 -2]
 [-2 -2 -2]
 [-2 -2 -2]]
[[ 3  8 15]
 [24 35 48]
 [63 80 99]]
[[0.33333333 0.5        0.6       ]
 [0.66666667 0.71428571 0.75      ]
 [0.77777778 0.8        0.81818182]]
tensor([[ 4,  6,  8],
        [10, 12, 14],
        [16, 18, 20]])
tensor([[-2, -2, -2],
        [-2, -2, -2],
        [-2, -2, -2]])
tensor([[ 3,  8, 15],
        [24, 35, 48],
        [63, 80, 99]])
tensor([[0.3333, 0.5000, 0.6000],
        [0.6667, 0.7143, 0.7500],
        [0.7778, 0.8000, 0.8182]])
'''
```

写成函数的形式（常见不常用）：

NumPy：

- 加法：`np.add(x1, x2)`
- 减法：`np.subtract(x1, x2)`
- 乘法：`np.multiply(x1, x2)`

PyTorch：

- 加法：`torch.add(x1, x2)`
- 减法：`torch.sub(x1, x2)`
- 乘法：`torch.mul(x1, x2)`

### 广播

逐元素计算的特例。

现有矩阵和向量：
$$
\mathrm{m}=\begin{bmatrix}1&2&3\\ 4&5&6\\ 7&8&9\end{bmatrix},\mathrm{v}=\begin{bmatrix}10\\ 20\\ 30\end{bmatrix}
$$

对于矩阵乘法，要求左侧矩阵的列数等于右侧矩阵的行数。 $m$ 与 $v$ 相乘为：
$$
\begin{bmatrix}1*10+2*20+3*30\\ 4*10+5*20+6*30\\ 7*10+8*20+9*30\end{bmatrix} = \begin{bmatrix}140\\320\\500\end{bmatrix}
$$
对于逐元素相乘，即哈达玛积，两者维度不一致的情况可以进行“广播”。 $m$ 与 $v$ 相乘为：
$$
\begin{bmatrix}1*10&2*10&3*10\\ 4*20&5*20&6*20\\ 7*30&8*30&9*30\end{bmatrix} = \begin{bmatrix}10&&20&&30\\ 80&&100&&120\\210&&240&&270\end{bmatrix}
$$

```python
# a = np.array([[1,2,3],[4,5,6],[7,8,9]])
a = np.arange(1, 10)
a = a.reshape(3, 3)
b = np.array([[10],[20],[30]])
print(a @ b)
print(a * b)
'''
[[140]
 [320]
 [500]]
[[ 10  20  30]
 [ 80 100 120]
 [210 240 270]]
 '''
```

### 矩阵乘法

矩阵乘法要求参与计算的矩阵维度符合矩阵乘法定义。

运算符：`a @ b`

写成函数的形式：

- NumPy：`np.dot(x1, x2)`
- PyTorch：`torch.matmul(x1, x2)`

```python
# NumPy
a = np.arange(1, 7).reshape(2, 3)
b = np.arange(3, 9).reshape(3, 2)
print(a @ b)
print(np.dot(a, b))

# PyTorch
x = torch.arange(1, 7).reshape(2, 3)
y = torch.arange(3, 9).reshape(3, 2)
print(x @ y)
print(torch.matmul(x, y))

'''
[[34 40]
 [79 94]]
[[34 40]
 [79 94]]
tensor([[34, 40],
        [79, 94]])
tensor([[34, 40],
        [79, 94]])
'''
```

### 批量矩阵相乘

这部分涉及到的方法比较混乱：

- NumPy 中，矩阵乘法有专门的函数，即点乘：`np.dot()`。其批量矩阵乘法用函数 `np.matmul()`。
- PyTorch 中，批量矩阵乘法和普通矩阵乘法是一个函数 `torch.matmul()`。
- NumPy array 和 Torch tensor 直接用运算符 `@` 都能完成批量矩阵乘法的操作。

```python
batch_size = 2
m, n, p = 3, 2, 3
a = np.random.randint(10, size=(batch_size, m, n))
b = np.random.randint(10, size=(batch_size, n, p))
# print(np.dot(a,b)) 这个会运算错误，达不到预期
print(np.matmul(a, b))
print(a @ b)

x = torch.randint(10, size=(batch_size, m, n))
y = torch.randint(10, size=(batch_size, n, p))
print(torch.matmul(x, y))
print(x @ y)

'''
[[[39 55 19]
  [17 79 12]
  [24 68 14]]

 [[61 45 74]
  [10  0 35]
  [33 25 38]]]
[[[39 55 19]
  [17 79 12]
  [24 68 14]]

 [[61 45 74]
  [10  0 35]
  [33 25 38]]]
tensor([[[32, 32, 24],
         [26, 20, 24],
         [72, 48, 72]],

        [[40, 15, 20],
         [54, 39, 24],
         [22, 27,  8]]])
tensor([[[32, 32, 24],
         [26, 20, 24],
         [72, 48, 72]],

        [[40, 15, 20],
         [54, 39, 24],
         [22, 27,  8]]])
'''
```

> 搞了半天，其实这些函数都可以用运算符代替，好像没有必须使用函数的时候。。。

### 其他矩阵运算

矩阵转置

```python
# numpy
a = np.random.randint(10, size=(2, 3))
b = np.transpose(a)
print(b.shape)

# pytorch
x = torch.randint(10, size=(2, 3))
y = torch.transpose(x, 0, 1)
print(y.shape)

y = torch.randint(10, size=(3, 2, 3))
# y.t() 大于二维的 tensor 不能用这个，会报错
y1 = torch.transpose(y, 0, 1)
print(y1.shape)
y2 = y.transpose(1, 2)
print(y2.shape)
y3 = y
y3.transpose(1, 2) # 这种是需要返回值才能工作的，直接这样并不会改变数据
print(y3.shape)
'''
(3, 2)
torch.Size([3, 2])
torch.Size([2, 3, 3])
torch.Size([3, 3, 2])
torch.Size([3, 2, 3])
'''
```

还有求逆、行列式计算、特征值和特征向量计算等等运算的函数，不是很常用。

## PyTorch 中设备选择与 CUDA 使用

```python
# 设置 device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(device)

# 如果有多个 GPU
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print(device)

# 直接在 cuda 上创建 tensor
x = torch.zeros(5, dtype=int, device=device)
print(x)

# 转移到 GPU
y = torch.zeros(5, dtype=float64, device='cpu')
print(y)
y = y.to(device)
print(y)

'''
cuda
cuda:0
tensor([0, 0, 0, 0, 0], device='cuda:0')
tensor([0., 0., 0., 0., 0.], dtype=torch.float64)
tensor([0., 0., 0., 0., 0.], device='cuda:0', dtype=torch.float64)
'''
```

## PyTorch 打印模型参数

```python
# model 是定义好的 PyTorch 模型
loss.backward()
for name, parms in model.named_parameters():	
    print('-->name:', name, '-->grad_requirs:',parms.requires_grad, \
        ' -->grad_value:',parms.grad)
```

## PyTorch 打印模型结构

注意，虽然模型是这样的，但是 forward 中才指定了模型中各个参数的使用方式，可能并不是按照这个顺序执行的。

```python
# model 是定义好的 PyTorch 模型
print(model)
'''
这是一个输出的样例
Model(
  (encoder): Encoder(
    (conv): ModuleList(
      (0): GCNConv(1433, 2048)
      (1): GCNConv(2048, 1024)
    )
    (bn1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (bn2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (ge): Genetation(
    (conv): GATConv(1024, 1024, heads=1)
    (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
'''
```



